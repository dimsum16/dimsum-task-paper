{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 22 days\n",
      "/Users/anders/anaconda/lib/python3.4/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in gold data and submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_dimsum_data(filename):\n",
    "    results = pd.read_csv(filename, sep=\"\\t\", names=['token_offset', 'form', 'lemma', 'pos', 'mwe', \n",
    "                                    'parent_offset', 'strength', 'supersense', 'sent_id'],\n",
    "                      quoting=3, na_filter=False)\n",
    "    results.supersense = results.supersense.str.replace('^$', 'O')\n",
    "\n",
    "    return results\n",
    "\n",
    "gold = read_dimsum_data(\"dimsum16.test\")\n",
    "tweet_mask = gold.sent_id.str.startswith(\"twe\")\n",
    "ted_mask = gold.sent_id.str.startswith(\"ted\")\n",
    "trustpilot_mask = gold.sent_id.str.startswith(\"trustpilot\")\n",
    "\n",
    "supersense_labels = sorted(set(gold.supersense.unique()) - {'O'})\n",
    "mwe_labels = sorted({'I', 'i'})\n",
    "\n",
    "submission_ids = \"106 108 211 214 227 248 249 254 255\".split(\" \")\n",
    "submissions = {\"S\" + submission_id: read_dimsum_data(submission_id + \".test.pred\")\n",
    "               for submission_id in submission_ids}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masks for relevant predictions with respect to gold data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "has_supersense = gold.supersense.isin(supersense_labels)\n",
    "has_mwe = gold.mwe.isin(mwe_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Extra) Reproduce scoring from results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred1 = submissions['S214']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "def score_entry(y_gold, y_pred, labels):\n",
    "    scores = {\n",
    "        'precision': precision_score(y_gold, y_pred, \n",
    "                                     average='micro', labels=labels),\n",
    "        'recall': recall_score(y_gold, y_pred, \n",
    "                               average='micro', labels=labels),\n",
    "        'f1': f1_score(y_gold, y_pred, \n",
    "                       average='micro', labels=labels)\n",
    "    }\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.57551440329218106,\n",
       " 'precision': 0.56221105527638193,\n",
       " 'recall': 0.58946259220231823}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_entry(gold['supersense'], pred1['supersense'], supersense_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.57496109285837804,\n",
       " 'precision': 0.58271994391868209,\n",
       " 'recall': 0.56740614334470985}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_entry(np.concatenate([gold.supersense, gold.mwe]), np.concatenate([pred1.supersense, pred1.mwe]), \n",
    "            labels=supersense_labels + mwe_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.722298221614\n",
      "0.473542600897\n",
      "0.572047670639\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(gold.mwe, pred1.mwe, average='micro', labels=mwe_labels))\n",
    "print(recall_score(gold.mwe, pred1.mwe, average='micro', labels=mwe_labels))\n",
    "print(f1_score(gold.mwe, pred1.mwe, average='micro', labels=mwe_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
