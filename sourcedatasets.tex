\begin{tabular}{@{}r@{~~}l@{~~}>{\raggedright\hangindent=1em}p{19.5em}@{~~}>{\raggedright\hangindent=1em}p{9.75em}@{~~}r@{~~}r@{~~}r@{~~}>{\smaller}r@{~~}>{\smaller}r@{}}
 & \textbf{Domain} & \textbf{Source corpus} & \textbf{UPOS (UD 1.2--style)} & \textbf{Docs} & \textbf{Sents} & \textbf{Words} 
 & \textbf{w$/$s}	
 & \textbf{$\lambda$types} \\
\midrule
\multirow{3}{*}{\rotatebox{90}{\datasplit{Train}}} & \dataset{Reviews} & STREUSLE 2.1 \textsmaller{\citep{schneider-15}} & Conv.~from PTB parses & 723 & 3,812 & 55,579 & 14.6 & 5,052 \\
& \dataset{Tweets} & Lowlands (tweets w/ URLs) \textsmaller{\citep{johannsen-14}} & Conv.~from Petrov-style & N/A & 200 & 3,062 & 15.3 & 1,201 \\
& \dataset{Tweets} & Ritter \textsmaller{\citep{ritter-11,johannsen-14}} & Conv.~from Petrov-style & N/A & 787 & 15,185 & 19.3 & 3,819 \\
\cmidrule{2-9}
& \multicolumn{3}{r}{\textbf{Train Total}}           && 4,799 & 73,826 & 15.4 & 7,988 \\
\midrule
\multirow{5}{*}{\rotatebox{90}{\datasplit{Test}\hspace{10pt}}} &	\dataset{Reviews} & Trustpilot \textsmaller{\citep{hovy-2015age}} & Conv.~from Petrov-style & N.A. & 340 & 6,357 & 18.7 & 1,365 \\
& \dataset{Tweets} & Tweebank \textsmaller{\citep{kong-14}} & Conv.~from TweetNLP POS in FUDG parses & N/A & 500 & 6,627 & 13.3 & 1,786 \\
& \dataset{TED} & NAIST-NTT ($\subset$ IWSLT train) \textsmaller{\citep{cettolo-2012wit3,neubig-2014naist}} & Conv.~from PTB parses & 10 & 100 & 2,187 & 21.9 & 630 \\
& \dataset{TED} & IWSLT test \textsmaller{\citep{cettolo-2012wit3}} & Auto & 6 & 60 & 1,329 & 22.2 & 457 \\
\cmidrule{2-9}
& \multicolumn{3}{r}{\textbf{Test Total}}	         && 1,000 & 16,500 & 16.5 & 3,160 \\
\midrule
\multicolumn{4}{r}{\textbf{\dataset{Reviews} Total}} && 4,152 & 61,936 & 14.9 & 5,477 \\
\multicolumn{4}{r}{\textbf{\dataset{Tweets} Total}}  && 1,487 & 24,874 & 16.7 & 5,464 \\
\multicolumn{4}{r}{\textbf{\dataset{TED} Total}}     &&   160 &  3,516 & 22.0 &   900 \\
\midrule
\multicolumn{4}{r}{\textbf{Grand Total}} && 5,799 & 90,326 & 15.6 & 9,321 \\
\end{tabular}
\caption[Source datasets and preprocessing]{Source datasets and preprocessing to obtain Universal POS tags (UPOS) 
according to the 17-tag scheme as defined in version 1.2 of the Universal Dependencies project. 
Most source corpora already contained some form of POS tags, so we automatically converted them to UPOS. 
However, not all the necessary distinctions are made in the original tagsets---e.g., auxiliaries are distinguished from 
main verbs in UD-style UPOS, but not in the Petrov-style, PTB, or TweetNLP POS tagsets.
If a gold parse was available, we used it to help disambiguate;
otherwise, disambiguation was done manually as a followup step. 
For the Tweebank data, our conversion procedure also modified the tokenization to be consistent with UPOS conventions for English 
(e.g., separating clitics).\endgraf\setlength{\parindent}{1em}
\textbf{$\lambda$types} stands for the number of unique lemmas.
Only some portions of the data group sentences into documents: N/A = not applicable; N.A. = not available.}